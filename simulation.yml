pdi:
  logging:
    level: "warn"

  metadata:
    pcoord_1d: int
    pcoord: { type: array, subtype: int, size: 2 }
    psize: { type: array, subtype: int, size: 2 }
    dsize: { type: array, subtype: int, size: 2 }
    MaxtimeSteps: int
    timestep: int
    mpi_per_node: int

  data:
    local_t:
      type: array
      subtype: double
      size: ['$dsize[0]', '$dsize[1]']
      subsize: ['$dsize[0] - 2', '$dsize[1] - 2']
      start: [1, 1]
    
  plugins:
    mpi:
    pycall:
      on_event:
        init:
          with: {rank: $pcoord_1d, iterations: $MaxtimeSteps, mpi_per_node: $mpi_per_node}
          exec: |
            import ray
            import logging
            import time
            import netifaces
            import gc

            # In this event we init ray, define all the tasks and create the actors
            ib = netifaces.ifaddresses('ib0')[netifaces.AF_INET][0]['addr'] # Infiniband address
            # concurrency=int(mpi_per_node)+2 # Actor concurrency value
            concurrency=4 # Actor concurrency value

            ray.init(address="auto", namespace="mpi", logging_level=logging.ERROR, _node_ip_address=ib)
            
            @ray.remote (resources={"actor":1}) # Resource actor indicates that the actor will be running in one simulation node
            class ProcessActor: 
                def __init__(self):
                    self.finished = False
                    self.queues = [] # Simulation data will be stored here
                    self.offset = int(rank) # Rank of the process that creates the actor
                    self.control = [0 for _ in range(iterations)] # Number of processes that have stored the data on each iteration
                    for i in range(mpi_per_node):
                        self.queues.append([ray.put(0) for _ in range(iterations)])
                    return
                
                # This method will wait until the client mark the analytics as finished
                def is_finished(self):
                    while(not(self.finished)):
                        pass
                    return True

                # Mark analytics as finished
                def finish(self):
                    self.finished=True
                    return
                
                # Each MPI process will call this method every iteration
                def add_value(self, mpid, result, iter):
                    iter=int(iter)
                    mpid=int(mpid)
                    self.queues[mpid%mpi_per_node][iter]=result[0]
                    self.control[iter] = self.control[iter]+1
                    return

                # The client will tell the actor to execute some tasks through this method
                def trigger(self, process_task: ray.remote_function.RemoteFunction, actor_task: ray.remote_function.RemoteFunction, iter: int, RayList, kept_iters):
                    iter = int(iter)
                    
                    while self.control[iter] < mpi_per_node:
                        pass # Ensure that all processes have stored its value
                    
                    tasks = RayList()
                    for mpid in range(mpi_per_node): # Remember that each actor just manages MPI_PER_NODE processes
                        # Execute one asynchronous task per process per iteration requested by the client
                        tasks.append(process_task.remote(mpid+self.offset, iter, RayList(self.queues[mpid][:iter+1])))
                        # Erase non-used data
                        if iter-kept_iters > 0:
                            self.queues[mpid][iter-kept_iters-1]=None

                    gc.collect()

                    # Execute the actor_task over all the results of the previous process_tasks if asked by the client
                    if actor_task:
                        return actor_task.remote(rank, iter, tasks)
                    else:
                        return tasks

            put_time = 0
            actor = None
            actorname = "ranktor"+str(rank - (rank%mpi_per_node)) # Common actor name for the processes within the same simulation node

            if rank%mpi_per_node == 0: # One process per node creates the actor
                actor = ProcessActor.options(max_concurrency=concurrency, name=actorname, namespace="mpi", lifetime="detached").remote()
            else: # The processes which have not created the actor look for it
                timeout = 10
                start = time.time()
                error = True
                while error:
                    try:
                        actor = ray.get_actor(actorname, namespace="mpi")
                        error = False
                    except Exception as e:
                        actor = None
                        elapsed_time = time.time() - start
                        if elapsed_time >= timeout:
                            raise Exception("Cannot get the Ray actors. Simulation may break.")

        Available:
          with: { i: $timestep, data: $local_t}
          exec: |
              # This event manages what is happening for each iteration in the simulation
              
              # Measure time spent in ray.put() instruction
              start = time.time() 
              d = ray.put(data)
              put_time = put_time + (time.time()-start)
              start = time.time()
              
              # Check that there is space available in plasma memory (1GB)
              status = ray.nodes()
              id = ray.get_runtime_context().get_node_id()
              flag = True
              while(flag):
                  for node in status:
                      if node['NodeID'] == id:
                          if node['Resources']['object_store_memory'] > 10**9:
                              flag = False
                          else:
                              break
                  status = ray.nodes()

              # Tell the actor to save the reference of the put object
              if rank%mpi_per_node == 0:
                  actor.add_value.remote(rank, [d], i)
              else:
                  actor.add_value.remote(rank, [d], i)

        analyze:
          exec: |
            # Print measured values
            if rank == 0:
                print("{:<21}".format("PUT_TIME:") + str(put_time)) # In process 0
                print("{:<21}".format("ACTOR_CONCURRENCY:") + str(concurrency))

            
            # Wait for the analytics finished
            if rank == 0:
              ref = [actor.is_finished.remote()]
              while(True):
                  f, _ = ray.wait(ref, timeout=1)
                  if len(f)>0:
                      break

        finish:
          exec: |
            ray.timeline(filename="timeline-client.json")
            ray.shutdown()
